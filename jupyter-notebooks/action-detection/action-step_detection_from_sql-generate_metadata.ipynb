{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b915e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages to read sqlite file\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time  \n",
    "import datetime\n",
    "import calendar\n",
    "import argparse\n",
    "\n",
    "# import packages to write a json file\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee3753",
   "metadata": {},
   "source": [
    "- Convert date string (HHMMSS.MS) to PTG timestamp format (epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "12a69814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date string (HHMMSS) to PTG timestamp format (epoch)\n",
    "def  utc_hms_date_to_epoch(utc_date_str):\n",
    "    # utc_date_str = '17:29:43.005'\n",
    "    datetime_value = datetime.datetime.strptime(utc_date_str, '%H:%M:%S.%f')\n",
    "    dt_now = datetime.datetime.now()\n",
    "    # set year, month, day of the datetime object to current date's year, month and day via replace\n",
    "    # since there is no Year, Month, Day info (this info is required to computed a positive epoch value. otherwise it will be negative (1900-01-01))\n",
    "    dt = datetime_value.replace(year=dt_now.year, month=dt_now.month, day=dt_now.day) # replace with current YYMMDD info\n",
    "    epoch_format = calendar.timegm(dt.timetuple())\n",
    "    ptg_timestamp_format = str(epoch_format*1000)+'-0'\n",
    "    return ptg_timestamp_format    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c1d063ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900-01-01 17:29:43.005000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1684430983000-0'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utc_hms_date_to_epoch(\"17:29:43.005\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e9ef16",
   "metadata": {},
   "source": [
    "Create a database connection to the SQLite database and return this as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8974684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by the db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file, uri=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return conn\n",
    "\n",
    "def get_dataframe_from_sqlite(db_file, table_name):\n",
    "    # fancy read-only connection\n",
    "    conn = create_connection(db_file)\n",
    "    # create the dataframe from a query\n",
    "    query = \"SELECT * FROM \" + table_name\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb5801",
   "metadata": {},
   "source": [
    "#### Getting actions from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7bfd4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions_json(df):\n",
    "    json_values = []\n",
    "    unique_actions = df[\"Event\"].unique()\n",
    "    \n",
    "    df2 = df[df['timestamp'].notnull()] # remove null timestamps\n",
    "    df3 = df2[pd.to_datetime(df2['timestamp'], errors='coerce',format='%H:%M:%S.%f').notnull()] # check correct format\n",
    "    uniqueTs = df3['timestamp'].unique()\n",
    "    for ts in uniqueTs:\n",
    "        detected_actions_per_ts = df[df['timestamp'] == ts]['Event'].values\n",
    "        row_dic = {\"timestamp\": utc_hms_date_to_epoch(ts) } # get time from sqlite file\n",
    "        for action in unique_actions:\n",
    "            if(action in list(detected_actions_per_ts)):\n",
    "                row_dic[action] = 1\n",
    "            else:\n",
    "                row_dic[action] = 0\n",
    "        json_values.append(row_dic)        \n",
    "        sorted_json_data = sorted(json_values, key=lambda d: d['timestamp'].split('-')[0])     \n",
    "    return sorted_json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72eae3a",
   "metadata": {},
   "source": [
    "### Getting actions from a SQLite database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b644e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'egovlp_action_steps_v10.json' # 'detic-image-fixed-labels.json'\n",
    "isFile = os.path.isfile(filename)\n",
    "\n",
    "df_table = get_dataframe_from_sqlite(\"0293_13.sqlite\", \"ocarina_mission_log\")\n",
    "\n",
    "json_data = get_actions_json(df_table)\n",
    "\n",
    "if (not isFile):\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(json_data, fp, indent=4)\n",
    "else:\n",
    "    print(f'An error occurred writing to {filename}.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7307d2",
   "metadata": {},
   "source": [
    "#### Getting steps from a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1fb7fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#   \"step_id\": 0,\n",
    "#   \"step_status\": \"NEW\",\n",
    "#   \"step_description\": \"Place tortilla on cutting board.\",\n",
    "#   \"error_status\": false,\n",
    "#   \"error_description\": \"\",\n",
    "#   \"timestamp\": \"1679339146083-0\"\n",
    "# }\n",
    "\n",
    "def get_steps_json(df):\n",
    "    json_values = []\n",
    "    \n",
    "    df2 = df[df['timestamp'].notnull()] # remove null timestamps\n",
    "    df3 = df2[pd.to_datetime(df2['timestamp'], errors='coerce',format='%H:%M:%S.%f').notnull()] # check correct format\n",
    "    uniqueTs = df3['timestamp'].unique()\n",
    "    for ts in uniqueTs:\n",
    "        detected_steps_per_ts = df[df['timestamp'] == ts]['Step'].values\n",
    "        step = list(detected_steps_per_ts)[0]\n",
    "        timestamp_value = utc_hms_date_to_epoch(ts)# get time from sqlite file\n",
    "        row_dic = {\"step_id\": step,\n",
    "                    \"step_status\": \"NEW\",\n",
    "                    \"step_description\": \"\",\n",
    "                    \"error_status\": False,\n",
    "                    \"error_description\": \"\",\n",
    "                    \"timestamp\": timestamp_value\n",
    "                   }\n",
    "        json_values.append(row_dic)        \n",
    "        sorted_json_data = sorted(json_values, key=lambda d: d['timestamp'].split('-')[0])     \n",
    "    return sorted_json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9787f",
   "metadata": {},
   "source": [
    "### Getting steps from a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a257905",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'reasoning_check_status_v10.json' # 'detic-image-fixed-labels.json'\n",
    "isFile = os.path.isfile(filename)\n",
    "\n",
    "df_table = get_dataframe_from_sqlite(\"0293_13.sqlite\", \"ocarina_mission_log\")\n",
    "\n",
    "json_data = get_steps_json(df_table)\n",
    "\n",
    "if (not isFile):\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(json_data, fp, indent=4)\n",
    "else:\n",
    "    print(f'An error occurred writing to {filename}.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3cfb5d",
   "metadata": {},
   "source": [
    "### Generating metadata from a objects json file and computing video duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5d8107ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "# required to install \"pip install moviepy\"\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def getMetadata(video_path, objects_file_path):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    # Opening JSON file that contains objects (it must be sorted by timestamps)\n",
    "    file_objects = open(objects_file_path)\n",
    "    # returns JSON object as a dictionary\n",
    "    data = json.load(file_objects)\n",
    "\n",
    "    metadata ={\n",
    "            \"duration_secs\": int(clip.duration),\n",
    "            \"first-entry\": data[0][\"timestamp\"],\n",
    "            \"last-entry\": data[len(data)-1][\"timestamp\"],\n",
    "        }\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bde7e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_path = \"ngc_0293_13.mp4\"\n",
    "objects_file_path = 'objects_from_sql_v9.json'\n",
    "filename = 'ngc_0293_13_additional_metadata_v1.json' # 'detic-image-fixed-labels.json'\n",
    "\n",
    "isFile = os.path.isfile(filename)\n",
    "json_data = getMetadata(video_path, objects_file_path)\n",
    "\n",
    "if (not isFile):\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(json_data, fp, indent=4)\n",
    "else:\n",
    "    print(f'An error occurred writing to {filename}.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb484e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
